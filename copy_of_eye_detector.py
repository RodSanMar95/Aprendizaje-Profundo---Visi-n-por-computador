# -*- coding: utf-8 -*-
"""Copy_of_Eye_detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VMVu4dx3-Psva_DFSfwjTi8uzl2e7HOW
"""

!pip install gdown
import gdown
import zipfile
import os

file_id = '1c6Gv3LB2mi3_7_gzN1q6e6echCk3sinF'
url = f'https://drive.google.com/uc?id={file_id}'

output = 'downloaded_file.zip'
gdown.download(url, output, quiet=False)

with zipfile.ZipFile(output, 'r') as zip_ref:
    zip_ref.extractall('extracted_folder')

os.remove(output)
print('Download and extraction completed successfully.')

extracted_items = os.listdir('extracted_folder')
print(f'Items in extracted_folder:')
for item in extracted_items:
    print(item)

import pandas as pd

csv_file_path = 'extracted_folder/data.csv'
df = pd.read_csv(csv_file_path)

!pip install lightning

!pip install seaborn
!pip install torchvision
import os
from dataclasses import dataclass
import lightning as L
import pandas as pd
import seaborn as sn
import torch
import random
import string
from PIL import Image, ImageDraw
from lightning.pytorch.loggers import CSVLogger
from lightning.pytorch.callbacks.early_stopping import EarlyStopping
from torch.optim.lr_scheduler import StepLR
from torch import nn
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from torchmetrics import MeanSquaredError
from torchvision import transforms, models
import matplotlib.pyplot as plt

@dataclass
class Config:
    save_dir: str = "logs-eyes/"
    batch_size: int = 16
    max_epochs: int = 4
    patience: int = 2
    accelerator: str = "auto"
    devices: int = 1
    learning_rate: float = 1e-4
    num_workers: int = 8

config = Config()

class CustomDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0]) # genera el path dentro del directorio y cogemos los nombres de la columna cero
        image = Image.open(img_name).convert("RGB")

        left_eye_x = self.data.iloc[idx, 2] / image.width # se ponderan estas posiciones en relativo a la imagen
        left_eye_y = self.data.iloc[idx, 3] / image.height
        right_eye_x = self.data.iloc[idx, 4] / image.width
        right_eye_y = self.data.iloc[idx, 5] / image.height

        # diccionario
        sample = {
            'image': image,
            'eyes': torch.tensor([left_eye_x, left_eye_y, right_eye_x, right_eye_y], dtype=float),
            'path' : img_name
        }

        # data aumentation
        if self.transform:
            sample['image'] = self.transform(sample['image'])

        return sample

# Define transforms for training
train_transform = transforms.Compose([
    transforms.Resize((224, 224), antialias=True),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1), # cambio HSV
    transforms.GaussianBlur(kernel_size=5), # filtro gaussiano
    transforms.ToTensor(), # convertir a tensor
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] # se normalizaron la media y la std a estos valores por r g y b
    ),  # imagenet normalization
])

# For validation and testing, apply only ToTensor and normalization
val_test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
    ),  # imagenet normalization
])

train_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=train_transform)
val_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=val_test_transform)
test_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=val_test_transform)

# Calculate sizes for splitting
total_size = len(train_dataset)
train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

# Split dataset into train, validation, and test
train_subset, val_subset, test_subset = random_split(
    range(total_size), [train_size, val_size, test_size]
)

# Create data loaders
train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=train_subset)
val_dataloader = DataLoader(val_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=val_subset)
test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=test_subset)

backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
print(backbone) # Transfer lerning de una resnet18, se descarga de models se pueden consultar arqu y datos
# eliminamos la ultima fc lineal por una fc 512 a 4, la entrada no se puede cambiar

class LitModel(L.LightningModule): # clase que entrena con un .fit() como sklearn

  def __init__(self, learning_rate):

      super().__init__() # activacion dle init de LightningModule
      self.learning_rate = learning_rate
      self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT) # trasfer learning
      self.eyes_head = torch.nn.Linear(self.backbone.fc.in_features, 4) # 4 positions, head se suele llamar a la red de lasificacion
      self.backbone.fc = nn.Sequential() # Remove current fc
      self.relu = torch.nn.ReLU()

      # Loss functions
      self.loss_eyes = nn.MSELoss(reduce='mean') # mean square error

      # Eyes, metricas
      self.train_eyes_mse = MeanSquaredError()
      self.val_eyes_mse = MeanSquaredError()
      self.test_eyes_mse = MeanSquaredError(squared=False) #RMSE

  def forward(self, x):
      # Run the backbone
      x = self.backbone(x)
      x_eyes = self.relu(self.eyes_head(x).squeeze()) # relu porque no tienen sentido posiciones de ojos negaticas
      # Return as tuple
      return x_eyes

  def training_step(self, batch, batch_idx):
      eyes = self.forward(batch['image'])
      # Weighted combination of loss functions.
      loss = self.loss_eyes(eyes, batch['eyes'].float())
      self.train_eyes_mse.update(eyes, batch['eyes'])
      return loss

  def validation_step(self, batch, batch_idx):
      eyes = self.forward(batch['image'])
      loss = self.loss_eyes(eyes, batch['eyes'].float())
      self.val_eyes_mse.update(eyes, batch['eyes'])
      self.log("val_loss", loss, prog_bar=True)
      self.log("val_mse_eyes", self.val_eyes_mse, prog_bar=True)
      self.log("train_mse_eyes", self.train_eyes_mse, prog_bar=True)

  def test_step(self, batch, batch_idx):
      eyes = self(batch['image'])
      loss = self.loss_eyes(eyes, batch['eyes'].float())
      self.test_eyes_mse.update(eyes, batch['eyes'])
      self.log("test_loss", loss, prog_bar=True)
      self.log("test_rmse_eyes", self.test_eyes_mse, prog_bar=True)

  def configure_optimizers(self):
      optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
      for param in self.parameters():
          param.data.clamp_(-0.5, 0.5)  # Apply weight clipping
      scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # half every 5 epoch.
      return [optimizer], [scheduler]  # Return both optimizer and scheduler

model = LitModel(config.learning_rate)
early_stop_callback = EarlyStopping(monitor="val_loss", patience=config.patience, verbose=False, mode="min")
# traquea el loss de validacion y si pasa de decrecer a crecer paramos que sino hay overfitting

trainer = L.Trainer(
    strategy='ddp_notebook',
    devices=config.devices,
    max_epochs=config.max_epochs,
    logger=CSVLogger(save_dir=config.save_dir),
    callbacks=[early_stop_callback],
)

trainer.fit(model, train_dataloader, val_dataloader)

trainer.test(ckpt_path="best", dataloaders=test_dataloader)

model.eval()

def draw_eye_boxes(image, eye_positions, box_color=(255, 0, 0), box_width=2):
        image_copy = image.copy()
        draw = ImageDraw.Draw(image_copy)
        # Extract the eye positions
        left_eye_x, left_eye_y, right_eye_x, right_eye_y = eye_positions
        left_eye_x = int(left_eye_x*image.width)
        right_eye_x = int(right_eye_x*image.width)
        left_eye_y = int(left_eye_y*image.height)
        right_eye_y = int(right_eye_y*image.height)
        # Define the coordinates of the bounding boxes
        bbox_size = 10
        left_eye_box = (left_eye_x - bbox_size, left_eye_y - bbox_size, left_eye_x + bbox_size, left_eye_y + bbox_size)
        right_eye_box = (right_eye_x - bbox_size, right_eye_y - bbox_size, right_eye_x + bbox_size, right_eye_y + bbox_size)
        # Draw bounding boxes around the eyes
        draw.rectangle(left_eye_box, outline=box_color, width=box_width)
        draw.rectangle(right_eye_box, outline=box_color, width=box_width)
        return image_copy

import matplotlib.pyplot as plt
import torchvision.transforms.functional as F

with torch.no_grad():
    batch = next(iter(test_dataloader))
    x_eyes = model(batch['image'])
    fig, axs = plt.subplots(1, len(batch), figsize=(15, 5))

    for ax, eyes, path in zip(axs, x_eyes, batch['path']):
        image = Image.open(path).convert("RGB")
        image_with_boxes = draw_eye_boxes(image, eyes)

        ax.imshow(image_with_boxes)
        ax.axis('off')

    plt.show()