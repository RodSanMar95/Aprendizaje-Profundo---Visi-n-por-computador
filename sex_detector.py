# -*- coding: utf-8 -*-
"""Sex-detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TsrdCnxSUndFKsEtLsZP4Ts-sCmfqmg4
"""

import gdown
import zipfile
import os

file_id = '1c6Gv3LB2mi3_7_gzN1q6e6echCk3sinF'
url = f'https://drive.google.com/uc?id={file_id}'

output = 'downloaded_file.zip'
gdown.download(url, output, quiet=False)

with zipfile.ZipFile(output, 'r') as zip_ref:
    zip_ref.extractall('extracted_folder')

os.remove(output)
print('Download and extraction completed successfully.')

extracted_items = os.listdir('extracted_folder')
print(f'Items in extracted_folder:')
for item in extracted_items:
    print(item)

import pandas as pd

csv_file_path = 'extracted_folder/data.csv'
df = pd.read_csv(csv_file_path)

!pip install lightning

import os
from dataclasses import dataclass
import lightning as L
import pandas as pd
import seaborn as sn
import torch
import random
import string
from PIL import Image, ImageDraw
from lightning.pytorch.loggers import CSVLogger
from lightning.pytorch.callbacks.early_stopping import EarlyStopping
from torch.optim.lr_scheduler import StepLR
from torch import nn
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from torchmetrics import Accuracy
from torchvision import transforms, models
import matplotlib.pyplot as plt

@dataclass
class Config:
    save_dir: str = "logs-eyes/"
    batch_size: int = 16
    max_epochs: int = 4
    patience: int = 2
    accelerator: str = "auto"
    devices: int = 1
    learning_rate: float = 1e-4
    num_workers: int = 8

config = Config()

class CustomDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])
        image = Image.open(img_name).convert("RGB")

        gender = 1 if  self.data.iloc[idx, 1] == 'male' else 0
        sample = {
            'image': image,
            'gender': torch.tensor([gender], dtype=torch.int32),
            'path' : img_name
        }

        if self.transform:
            sample['image'] = self.transform(sample['image'])

        return sample

# Define transforms for training
train_transform = transforms.Compose([
    transforms.Resize((224, 224), antialias=True),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),
    transforms.GaussianBlur(kernel_size=5),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
    ),  # imagenet normalization
])

# For validation and testing, apply only ToTensor and normalization
val_test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
    ),  # imagenet normalization
])

train_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=train_transform)
val_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=val_test_transform)
test_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=val_test_transform)

# Calculate sizes for splitting
total_size = len(train_dataset)
train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

# Split dataset into train, validation, and test
train_subset, val_subset, test_subset = random_split(
    range(total_size), [train_size, val_size, test_size]
)

# Create data loaders
train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=train_subset)
val_dataloader = DataLoader(val_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=val_subset)
test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=test_subset)

backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
print(backbone)

class LitModel(L.LightningModule):

    def __init__(self, learning_rate):
        super().__init__()
        self.learning_rate = learning_rate
        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        self.gender = torch.nn.Linear(self.backbone.fc.in_features, 1)  # Para la predicción de género
        self.backbone.fc = nn.Sequential()  # Eliminar la capa fully connected actual
        self.sigmoid = torch.nn.Sigmoid()

        # Función de pérdida
        self.loss_sex = nn.BCELoss(reduction='mean')

        # Métricas de precisión
        self.accuracy_train = Accuracy(task="binary")
        self.accuracy_test = Accuracy(task="binary")
        self.accuracy_val = Accuracy(task="binary")

    def forward(self, x):
        # Ejecutar el backbone
        x = self.backbone(x)
        x_sex = self.sigmoid(self.gender(x).squeeze(-1))  # Mantener el tamaño correcto
        # Devolver como tupla
        return x_sex

    def training_step(self, batch, batch_idx):
        sex_pred = self.forward(batch['image'])
        # Ajustar dimensiones de las etiquetas
        gender_labels = batch['gender'].float().squeeze(1)
        # Calcular la pérdida
        loss = self.loss_sex(sex_pred, gender_labels)  # Asegurar que dimensiones coinciden
        # Actualizar la precisión de entrenamiento
        self.accuracy_train.update(sex_pred, gender_labels)
        self.log("train_loss", loss, prog_bar=True)
        self.log("train_acc_sex", self.accuracy_train, prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        sex_pred = self.forward(batch['image'])
        # Ajustar dimensiones de las etiquetas
        gender_labels = batch['gender'].float().squeeze(1)
        # Calcular la pérdida de validación
        loss = self.loss_sex(sex_pred, gender_labels)
        # Actualizar la precisión de validación
        self.accuracy_val.update(sex_pred, gender_labels)
        self.log("val_loss", loss, prog_bar=True)
        self.log("val_acc_sex", self.accuracy_val, prog_bar=True)

    def test_step(self, batch, batch_idx):
        gender = self(batch['image'])
        # Ajustar dimensiones de las etiquetas
        gender_labels = batch['gender'].float().squeeze(1)
        # Calcular la pérdida de prueba
        loss = self.loss_sex(gender, gender_labels)
        # Actualizar la precisión de prueba
        self.accuracy_test.update(gender, gender_labels)
        self.log("test_loss", loss, prog_bar=True)
        self.log("test_accuracy", self.accuracy_test, prog_bar=True)

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        for param in self.parameters():
            param.data.clamp_(-0.5, 0.5)  # Aplicar weight clipping
        scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # Reducir a la mitad cada 5 épocas
        return [optimizer], [scheduler]  # Devolver tanto el optimizador como el scheduler

model = LitModel(config.learning_rate)
early_stop_callback = EarlyStopping(monitor="val_loss", patience=config.patience, verbose=False, mode="min")

trainer = L.Trainer(
    strategy='ddp_notebook',
    devices=config.devices,
    max_epochs=config.max_epochs,
    logger=CSVLogger(save_dir=config.save_dir),
    callbacks=[early_stop_callback],
)

trainer.fit(model, train_dataloader, val_dataloader)

trainer.test(ckpt_path="best", dataloaders=test_dataloader)

model.eval()

