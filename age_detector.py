# -*- coding: utf-8 -*-
"""Age_detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qMWseSqzI2f_n25vpx7yeO0o9JtOaz_1
"""

import gdown
import zipfile
import os

file_id = '1c6Gv3LB2mi3_7_gzN1q6e6echCk3sinF'
url = f'https://drive.google.com/uc?id={file_id}'

output = 'downloaded_file.zip'
gdown.download(url, output, quiet=False)

with zipfile.ZipFile(output, 'r') as zip_ref:
    zip_ref.extractall('extracted_folder')

os.remove(output)
print('Download and extraction completed successfully.')

extracted_items = os.listdir('extracted_folder')
print(f'Items in extracted_folder:')
for item in extracted_items:
    print(item)

import pandas as pd

csv_file_path = 'extracted_folder/data.csv'
df = pd.read_csv(csv_file_path)

!pip install lightning

import os
from dataclasses import dataclass
import lightning as L
import pandas as pd
import seaborn as sn
import torch
import random
import string
from PIL import Image, ImageDraw
from lightning.pytorch.loggers import CSVLogger
from lightning.pytorch.callbacks.early_stopping import EarlyStopping
from torch.optim.lr_scheduler import StepLR
from torch import nn
from torch.nn import functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from torchmetrics import MeanSquaredError, Accuracy
from torchvision import transforms, models
import matplotlib.pyplot as plt

@dataclass
class Config:
    save_dir: str = "logs-eyes/"
    batch_size: int = 16
    max_epochs: int = 4
    patience: int = 2
    accelerator: str = "auto"
    devices: int = 1
    learning_rate: float = 1e-4
    num_workers: int = 8

config = Config()

class CustomDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])
        image = Image.open(img_name).convert("RGB")

        age = self.data.iloc[idx, 6] / self.data.iloc[:, 6].max()

        sample = {
            'image': image,
            'age': torch.tensor(age, dtype=float),
            'path' : img_name
        }

        if self.transform:
            sample['image'] = self.transform(sample['image'])

        return sample

# Define transforms for training
train_transform = transforms.Compose([
    transforms.Resize((224, 224), antialias=True),
    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),
    transforms.GaussianBlur(kernel_size=5),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
    ),  # imagenet normalization
])

# For validation and testing, apply only ToTensor and normalization
val_test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
    ),  # imagenet normalization
])

train_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=train_transform)
val_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=val_test_transform)
test_dataset = CustomDataset('extracted_folder/data.csv', 'extracted_folder/images', transform=val_test_transform)

# Calculate sizes for splitting
total_size = len(train_dataset)
train_size = int(0.7 * total_size)
val_size = int(0.15 * total_size)
test_size = total_size - train_size - val_size

# Split dataset into train, validation, and test
train_subset, val_subset, test_subset = random_split(
    range(total_size), [train_size, val_size, test_size]
)

# Create data loaders
train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=train_subset)
val_dataloader = DataLoader(val_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=val_subset)
test_dataloader = DataLoader(test_dataset, batch_size=config.batch_size, num_workers=config.num_workers, sampler=test_subset)

backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
print(backbone)

class LitModel(L.LightningModule):

    def __init__(self, learning_rate):
        super().__init__()
        self.learning_rate = learning_rate
        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
        self.age_head = torch.nn.Linear(self.backbone.fc.in_features, 1)  # Predicción de la edad
        self.backbone.fc = nn.Sequential()  # Eliminar la capa fully connected actual
        self.relu = torch.nn.ReLU()

        # Función de pérdida
        self.loss_age = nn.MSELoss(reduction='mean')  # Corregido 'reduce' a 'reduction'

        # Métricas
        self.train_age_mse = MeanSquaredError()  # MSE para entrenamiento
        self.val_age_mse = MeanSquaredError()    # MSE para validación
        self.test_age_rmse = MeanSquaredError(squared=False)  # RMSE para prueba

    def forward(self, x):
        # Ejecutar el backbone
        x = self.backbone(x)
        x_age = self.relu(self.age_head(x).squeeze())
        return x_age

    def training_step(self, batch, batch_idx):
        age_pred = self.forward(batch['image'])
        # Calcular la pérdida de edad
        loss = self.loss_age(age_pred, batch['age'].float())
        # Actualizar la métrica de MSE
        self.train_age_mse.update(age_pred, batch['age'].float())
        self.log("train_loss", loss, prog_bar=True)
        self.log("train_mse_age", self.train_age_mse, prog_bar=True)
        return loss

    def validation_step(self, batch, batch_idx):
        age_pred = self.forward(batch['image'])
        # Calcular la pérdida de validación
        loss = self.loss_age(age_pred, batch['age'].float())
        # Actualizar la métrica de MSE de validación
        self.val_age_mse.update(age_pred, batch['age'].float())
        self.log("val_loss", loss, prog_bar=True)
        self.log("val_mse_age", self.val_age_mse, prog_bar=True)

    def test_step(self, batch, batch_idx):
        age_pred = self(batch['image'])
        # Calcular la pérdida en prueba
        loss = self.loss_age(age_pred, batch['age'].float())
        # Actualizar la métrica de RMSE en prueba
        self.test_age_rmse.update(age_pred, batch['age'].float())
        self.log("test_loss", loss, prog_bar=True)
        self.log("test_rmse_age", self.test_age_rmse, prog_bar=True)

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        for param in self.parameters():
            param.data.clamp_(-0.5, 0.5)  # Aplicar weight clipping
        scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # Reducir a la mitad cada 5 épocas
        return [optimizer], [scheduler]

model = LitModel(config.learning_rate)
early_stop_callback = EarlyStopping(monitor="val_loss", patience=config.patience, verbose=False, mode="min")

trainer = L.Trainer(
    devices=config.devices,
    max_epochs=config.max_epochs,
    logger=CSVLogger(save_dir=config.save_dir),
    callbacks=[early_stop_callback],
)

trainer.fit(model, train_dataloader, val_dataloader)

trainer.test(ckpt_path="best", dataloaders=test_dataloader)

model.eval()



